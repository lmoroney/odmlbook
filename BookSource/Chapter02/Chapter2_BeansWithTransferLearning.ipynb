{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPF6Tm1Xn_Px"
      },
      "outputs": [],
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\")\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \\\"AS IS\\\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs6665391bst"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0cKXo_cW25V"
      },
      "outputs": [],
      "source": [
        "# TensorFlow Hub는 모델을 저장하는 저장소입니다.\n",
        "# 여기서 이미 학습된 모델을 가져오겠습니다.\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xd0U-bRL1v5m"
      },
      "outputs": [],
      "source": [
        "# beans 데이터셋을 불러오기위해 TFDS를 사용합니다.\n",
        "# '개발자를 위한 머신러닝&딥러닝' 책에서 TFDS를 사용법을 설명합니다.\n",
        "(ds_train, ds_validation, ds_test), ds_info = tfds.load(\n",
        "    name = 'beans', \n",
        "    split = ['train', 'validation', 'test'],\n",
        "    as_supervised = True,\n",
        "    with_info = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAboigDC1yKV"
      },
      "outputs": [],
      "source": [
        "# 이제 모델을 학습하기 위해 TFDS의 데이터 처리를 설정합니다.\n",
        "batch_size=32\n",
        "def map_data(image, label, target_height = 224, target_width = 224):\n",
        "    \"\"\"Normalizes images: `unit8` -> `float32` and resizes images\n",
        "    by keeping the aspect ratio the same without distortion.\"\"\"\n",
        "    image = tf.cast(image, tf.float32)/255.\n",
        "    image = tf.image.resize_with_crop_or_pad(image, target_height, target_width)\n",
        "    return image, label\n",
        "\n",
        "ds_train = ds_train.map(map_data)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
        "ds_train = ds_train.batch(batch_size)\n",
        "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "ds_validation = ds_validation.map(map_data)\n",
        "ds_validation = ds_validation.batch(batch_size)\n",
        "ds_validation = ds_validation.cache()\n",
        "ds_validation = ds_validation.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(map_data)\n",
        "ds_test = ds_test.batch(batch_size)\n",
        "ds_test = ds_test.cache()\n",
        "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXvozLrGW7VE"
      },
      "outputs": [],
      "source": [
        "# 여러가지 다른 모델로 실험해볼 수 있습니다.\n",
        "# 아래 주석처리한 것은 카사바 병균(Cassava diseases) 데이터셋에대해 학습된 모델입니다.\n",
        "# 두번째는 모바일 앱에 주로 사용되는 MobileNet이라는 모델입니다.\n",
        "#model_handle = \"https://tfhub.dev/google/cropnet/feature_vector/cassava_disease_V1/1\"\n",
        "model_handle = \"https://tfhub.dev/google/imagenet/mobilenet_v2_035_224/feature_vector/4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_L0hExwXJko"
      },
      "outputs": [],
      "source": [
        "# 이제 hub에서 모델을 가져와 'Feature Vector'라고 부르겠습니다.\n",
        "# 이 레이어를 우리 모델에 추가합니다.\n",
        "feature_vector = hub.KerasLayer(model_handle, trainable=False,\n",
        "                               input_shape=(224, 224, 3))\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  feature_vector,\n",
        "  tf.keras.layers.Dense(3, activation = 'softmax'),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IL-2eNlj9bp"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGjV_UIx2rr0"
      },
      "outputs": [],
      "source": [
        "# 모델을 학습할 때 사용하는 파라미터를 정의하는 곳입니다.\n",
        "# 손실 함수(loss function)과 최적화기(optimizer)는 학습 방식을 정하게 됩니다.\n",
        "model.compile(\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    optimizer = tf.keras.optimizers.Adam(.001),\n",
        "    metrics = ['accuracy'],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTevBM1b2uCW"
      },
      "outputs": [],
      "source": [
        "# 모델을 학습할 수 있습니다. Colab의 GPU를 사용하면 20 에폭이 1분 안에 완료됩니다.\n",
        "num_epochs = 20\n",
        "history = model.fit(\n",
        "    ds_train,\n",
        "    epochs = num_epochs,\n",
        "    validation_data = ds_validation,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L03ga_j5KGHI"
      },
      "outputs": [],
      "source": [
        "# 학습된 모델을 saved_model 포맷으로 저장하는데, 나중에는 JS나 TFLite로 변환할 수 있습니다.\n",
        "tf.saved_model.save(model, '/tmp/saved_model/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UA9i5VP12xHt"
      },
      "outputs": [],
      "source": [
        "# 여기는 학습된 모델의 손실과 정확도 그래프를 나타냅니다.\n",
        "# 정확도는 시간이 지남에 따라 올라가야하고, 손실은 내려가야합니다.\n",
        "# 여기에는 2개의 그래프가 있습니다. 하나는 학습 데이터에대한 그래프인데, 모델이 이미지를 레이블로 잘 찾아내는지 파악하는데 사용됩니다. \n",
        "# 다른 하나는 검증 데이터에 대한 그래프인데, 잘 맞는지를 위한건 아니고, 모델이 한번도 본 적 없는 데이터를 얼마나 잘 맞추는지에대한 지표입니다. \n",
        "# 좋은 모델이라면 이 두 곡선이 결국 가까워야합니다.\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs_range = range(num_epochs)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()\n",
        "\n",
        "# 이 모델은 15 에폭 이후에 정확도가 떨어지는 모습을 보여줍니다.\n",
        "# 이것은 오버피팅의 신호이므로 좋은 모델이 아닙니다.\n",
        "# 하지만 지금 예제에서는 이정도로도 충분합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn3MTN5D4JiN"
      },
      "outputs": [],
      "source": [
        "# 오버피팅은 최종 테스트 정확도에서 입증됩니다.\n",
        "# 정확도가 92%인데, 테스트 정확도가 89%입니다.\n",
        "# 이는 모델이 학습하는 동안 '보았던' 데이터에 대해 더 잘 동작한다는 의미이고, \n",
        "# 처음보는 데이터는 잘 동작하지 않는다는 의미입니다.\n",
        "\n",
        "test_loss, test_acc = model.evaluate(ds_test)\n",
        "print('n Final test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAdhU-beKPv1"
      },
      "outputs": [],
      "source": [
        "def return_class_labels(ds):\n",
        "    \"\"\"`DatasetV1Adapter` object로부터 클래스 레이블 리스트를 반환\"\"\"\n",
        "    l_labels = []\n",
        "    for _, labels in ds.take(-1):\n",
        "        labels = labels.numpy()\n",
        "        l_labels.append(labels[:])\n",
        "    return [item for sublist in l_labels for item in sublist]\n",
        "\n",
        "def get_text_label(labelval):\n",
        "  labels = {\n",
        "      0: \"Angular Leaf Spot\",\n",
        "      1: \"Leaf Rust\",\n",
        "      2: \"Healthy\"\n",
        "  }\n",
        "  return labels.get(labelval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICAFae9D4SPk"
      },
      "outputs": [],
      "source": [
        "# 이 코드는 이미지를 플롯으로 그리고, 실제 레이블(진단된 질병)과 예측 레이블(모델이 추론한 질병 결과)을 보여줍니다.\n",
        "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
        "normalized_probs = probability_model.predict(ds_test)\n",
        "predicted_labels = np.argmax(normalized_probs, axis = 1)\n",
        "actual_labels = return_class_labels(ds_test)\n",
        "\n",
        "# 테스트 이미지입니다\n",
        "example = ds_test.take(1)\n",
        "for sample in example:\n",
        "    image = sample[0]\n",
        "    image = image.numpy()\n",
        "\n",
        "n_cols, n_rows = 4, 4\n",
        "plt.rcParams['figure.figsize'] = [n_cols*8, n_rows*8]\n",
        "\n",
        "fig = plt.figure()\n",
        "for i in range(1, n_cols*n_rows + 1):\n",
        "    ax = fig.add_subplot(n_rows, n_cols,i)\n",
        "    ax.text(5, -9, \"actual: \" + get_text_label(actual_labels[i]) + \", predicted: \" + get_text_label(predicted_labels[i]) ,\n",
        "            color = 'red', fontsize = 15)\n",
        "    ax.imshow(image[i, :, :, :], cmap = plt.get_cmap(\"jet\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Chapter2_BeansWithTransferLearning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
